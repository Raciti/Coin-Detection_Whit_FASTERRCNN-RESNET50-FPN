{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rPV1vsnWjqC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1QcfMCxWzEX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_sfjNCkW5y7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "import ast\n",
        "from torchvision.io import read_image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYAJrpg4AT_J"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOXyf-9lW7Jz"
      },
      "outputs": [],
      "source": [
        "csv_path = \"/content/drive/MyDrive/Colab_Notebooks/Machine_Learning/Progetto/Dataset/dataset_pr.csv\"\n",
        "img_path = \"/content/drive/MyDrive/Colab_Notebooks/Machine_Learning/Progetto/Dataset/Images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1URa5_5DXANR",
        "outputId": "e29d8726-f970-483c-b018-eec180adca58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset caricato correttamente numero immagini: 600\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  class CoinDataset(Dataset):\n",
        "    \"\"\"Euro Coin dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, width, height,transforms=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.coin_frame = pd.read_csv(csv_file, header = None)\n",
        "        print(\"Dataset caricato correttamente numero immagini:\",len(self.coin_frame))\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transforms\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.classes = [_, '10_cent']\n",
        "\n",
        "    def getClass(self):\n",
        "      return len(self.classes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.coin_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.coin_frame.iloc[idx, 0])\n",
        "        image = cv2.imread(img_name)\n",
        "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        img_res = cv2.resize(img_rgb, (self.width, self.height), cv2.INTER_AREA)\n",
        "        img_res /= 255.0\n",
        "\n",
        "        label = torch.tensor(ast.literal_eval(self.coin_frame.iloc[idx, 1]))\n",
        "        box = torch.tensor(ast.literal_eval(self.coin_frame.iloc[idx, 2])).unsqueeze(0)\n",
        "        box /= 150\n",
        "\n",
        "\n",
        "        sample = {'image': image, 'label': label, 'box' : box}\n",
        "\n",
        "        area = (box[:, 3] - box[:, 1]) * (box[:, 2] - box[:, 0])\n",
        "        iscrowd = torch.zeros((box.shape[0],), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target['boxes'] = sample['box']\n",
        "        target['labels'] =  sample['label']\n",
        "        target['area'] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        target[\"image_id\"] = torch.tensor([idx])\n",
        "\n",
        "        if self.transforms:\n",
        "\n",
        "              sample = self.transforms(image = img_res,\n",
        "                                      bboxes = target['boxes'],\n",
        "                                      labels = sample['label'])\n",
        "\n",
        "              img_res = sample['image']\n",
        "              target['boxes'] = torch.Tensor(sample['bboxes'])\n",
        "\n",
        "\n",
        "\n",
        "        return img_res, target\n",
        "\n",
        "  dataset = CoinDataset(csv_path, img_path, 150 ,150)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDhSCFddkL9A"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlK4gcyVaDKN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import cv2\n",
        "\n",
        "from xml.etree import ElementTree as et\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVrk6aBgXEmB"
      },
      "outputs": [],
      "source": [
        "def plot_img_bbox(img, target):\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    fig.set_size_inches(5,5)\n",
        "    a.imshow(img)\n",
        "    for box in (target['boxes']):\n",
        "        x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
        "        rect = patches.Rectangle((x, y),\n",
        "                                 width, height,\n",
        "                                 linewidth = 2,\n",
        "                                 edgecolor = 'r',\n",
        "                                 facecolor = 'none')\n",
        "\n",
        "        a.add_patch(rect)\n",
        "    a.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "img, target = dataset[25]\n",
        "plot_img_bbox(img, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jejahnHIb9hG"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZxUq78hbsVF"
      },
      "outputs": [],
      "source": [
        "def get_object_detection_model(num_classes):\n",
        "\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F59ojFPOcBml"
      },
      "outputs": [],
      "source": [
        "def get_transform(train):\n",
        "\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "                            A.HorizontalFlip(0.5),\n",
        "                            ToTensorV2(p=1.0)\n",
        "                        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "    else:\n",
        "        return A.Compose([\n",
        "                            ToTensorV2(p=1.0)\n",
        "                        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OECgpBSMcLli"
      },
      "outputs": [],
      "source": [
        "dataset =  CoinDataset(csv_path, img_path, 150, 150, transforms= get_transform(train=True))\n",
        "dataset_test =  CoinDataset(csv_path, img_path, 150, 150, transforms= get_transform(train=False))\n",
        "\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "\n",
        "test_split = 0.2\n",
        "tsize = int(len(dataset)*test_split)\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-tsize])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-tsize:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=4, shuffle=True, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=4, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-HV7KbTjIgf"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmnBhrgKhhIK"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "model = get_object_detection_model(num_classes)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fqGsioeCl7t"
      },
      "outputs": [],
      "source": [
        "print(model.state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTzmrFcKs1ta"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    lr_scheduler.step()\n",
        "    evaluate(model, data_loader_test, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrYPGM7XoGm6"
      },
      "source": [
        "# Salvataggio del modello e dei pesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUYMajPghOto"
      },
      "outputs": [],
      "source": [
        "path_model =  \"/content/drive/MyDrive/Colab_Notebooks/Machine_Learning/Progetto/CheckPoint/faster_rcnn_v2.onnx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObRf341LzYfx"
      },
      "outputs": [],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgluYyXyUgPY"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "input = torch.randn(1, 3, 150, 150)\n",
        "print(input.shape)\n",
        "torch.onnx.export(model, input, path_model, export_params=True, opset_version = 17, input_names = ['image'], output_names = ['boxes', 'labels', 'scores'])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}